{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "v7BB5pi79QA7"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "from langchain_ollama import ChatOllama\n",
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "from langchain_classic.chains.retrieval import create_retrieval_chain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-1YFOyu4iCR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcKICikoWyGc"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "77bd2b18"
      },
      "outputs": [],
      "source": [
        "#data ingest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9I_1BBWGK6E"
      },
      "outputs": [],
      "source": [
        "def ingest():\n",
        "    loader = TextLoader(\"/content/speech.txt\")\n",
        "    pages = loader.load()   \n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=0\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "    print(f\"Split {len(pages)} documents into {len(chunks)} chunks.\")\n",
        "\n",
        "    embedding = FastEmbedEmbeddings()\n",
        "\n",
        "    chroma = Chroma.from_documents(\n",
        "        documents=chunks,\n",
        "        embedding=embedding,\n",
        "        persist_directory=\"./chroma_database\",\n",
        "        collection_name=\"speech_collection\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_XBksGCHfLL",
        "outputId": "883f419b-926a-4233-dec5-04b4e1e1ac9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split 1 documents into 1 chunks.\n"
          ]
        }
      ],
      "source": [
        "ingest()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McbwfBW4G7qX",
        "outputId": "2df0ed8a-3da0-4095-d875-5c0cb905fba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split 1 documents into 1 chunks.\n"
          ]
        }
      ],
      "source": [
        "ingest()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "SkWHRwDwHgSS"
      },
      "outputs": [],
      "source": [
        "def rag_chain():\n",
        "    model = ChatOllama(model=\"mistral\")\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a friendly assistant. Answer the question based ONLY on the context below.\n",
        "If you don't know the answer, reply: \"No context available for this question: {input}\"\n",
        "\n",
        "Question: {input}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\")\n",
        "\n",
        "    embedding = FastEmbedEmbeddings()\n",
        "\n",
        "    vector_store = Chroma(\n",
        "        persist_directory=\"./chroma_database\",\n",
        "        embedding_function=embedding,\n",
        "        collection_name=\"speech_collection\"\n",
        "    )\n",
        "\n",
        "    retriever = vector_store.as_retriever(\n",
        "        search_type=\"similarity\",\n",
        "        search_kwargs={\"k\": 1}\n",
        "    )\n",
        "\n",
        "    text_chain = create_stuff_documents_chain(model, prompt)\n",
        "    retrieval_chain = create_retrieval_chain(retriever, text_chain)\n",
        "    return retrieval_chain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "DZDCxo1ptycg"
      },
      "outputs": [],
      "source": [
        "def ask(query: str):\n",
        "    #\n",
        "    chain = rag_chain()\n",
        "    # invoke chain\n",
        "    result = chain.invoke({\"input\": query})\n",
        "    # print results\n",
        "    print(result[\"answer\"])\n",
        "    for doc in result[\"context\"]:\n",
        "        print(\"Source: \", doc.metadata[\"source\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ask Question to get relevant information from the document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4p4KNxUxvsT",
        "outputId": "c860d67c-8cab-4f77-8360-1cd7deaba30d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " You must take a stand against the belief in the sanctity of the shastras.\n",
            "Source:  /content/speech.txt\n"
          ]
        }
      ],
      "source": [
        "ask(\"you must take a stand against what ? \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3PB78W900SH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dadbffa9",
        "outputId": "df960ae8-0b3a-4a7c-90a3-75119f7a60c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME              ID              SIZE      MODIFIED       \n",
            "mistral:latest    6577803aa9a0    4.4 GB    12 minutes ago    \n"
          ]
        }
      ],
      "source": [
        "!ollama list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "820ca086",
        "outputId": "c36b834a-5573-4c9c-bc2e-44ae69f168f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: listen tcp 127.0.0.1:11434: bind: address already in use\n"
          ]
        }
      ],
      "source": [
        "!ollama serve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpwBWjPMxs1t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_byvHfwxtTw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9Bw4rtzwA4F"
      },
      "outputs": [],
      "source": [
        "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIP6JKgZGprPpKfS7YwQK9r8Fg21E9EKvcDb0BXLXWwmM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60z-vW-CwrKP",
        "outputId": "54c6d854-65b3-4eac-9568-963a03a876a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ],
      "source": [
        "!ollama pull mistral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-yCygZXxD0q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
